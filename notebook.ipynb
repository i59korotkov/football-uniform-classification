{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Задача из отбора на стажировку в АНО «ЦИСМ» 2021.01.20\n\nВыполнил Коротков Илья","metadata":{"id":"ocs_cfToLBhP"}},{"cell_type":"markdown","source":"**У меня не получилось запустить итоговый файл с решением на платформе Kaggle, так как я потратил всё время графического ускорителя. Прикладываю ссылку на решение в Google Colab, в котором есть выводы всех ячеек.**\n\nСсылка на решение в Google Colab - https://colab.research.google.com/drive/1lb54XXjysEqBCSjeIXR7dN0s6MWMffbv?usp=sharing\n\nСсылка на видео с описанием решения - https://drive.google.com/file/d/1Ky1aMFGfz34Wb3eWeXvs2KgxjgGYtwk3/view?usp=sharing","metadata":{}},{"cell_type":"code","source":"from os import listdir\nfrom os.path import join, isfile, isdir\nfrom PIL import Image\n\nimport torch\nfrom torch.utils.data import Dataset, SubsetRandomSampler\nfrom torchvision import transforms\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib import image\n%matplotlib inline\n\ndevice = torch.device('cuda:0')","metadata":{"id":"Ny8lQa-S5ehy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Постановка задачи\n\nВ данной задаче вам необходимо классифицировать футбольные команды по их форме. Обучающая выборка состоит 3 408 фото, разбитых на 10 футбольных команд: Arsenal, Chelsea, Liverpool, Manchester City, Manchester United, Real Madrid, Barcelona, Bayern Munich, Paris Saint-Germain, Juventus.\nВ тестовой выборке 1 177 фото. Пример сабмита содержится в файле sample_submission.csv. Лейблы в сабмите должны быть закодированы следующим образом:\n\nArsenal: 0, Barcelona: 1, Bayern: 2, Chelsea: 3, Juventus: 4, Liverpool: 5, ManchesterCity: 6, ManchesterUnited: 7, PSG: 8, Real: 9\n\nВам необходимо построить модель нейронной сети для классификации футбольной формы. В качестве метрики выбрана F1 Macro.","metadata":{"id":"0iypZq4SLJlJ"}},{"cell_type":"markdown","source":"# 2. Загрузка данных","metadata":{"id":"CYLyVGrdLV4-"}},{"cell_type":"markdown","source":"Загрузим и распакуем заранее подготовленные данные с Google диска.","metadata":{"id":"D33sRiI6kPk-"}},{"cell_type":"code","source":"!pip install gdown","metadata":{"id":"STHggZiajtM7","outputId":"0e394738-85a0-4025-a978-76b066b68749"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 1cnZ7__tXkH7cZjOEiZuKGzF4CVKFgiSt -O \"/content/train.zip\"\n!gdown --id 1oyqP49cgJG5oxIBdiHMQoNsHonCCPasf -O \"/content/test.zip\"","metadata":{"id":"5I32-YcEjtdI","outputId":"fba4a013-865f-4856-f3bb-1269573f74c6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!unzip \"/content/train.zip\" -d \"/content/\"\n!unzip \"/content/test.zip\" -d \"/content/\"","metadata":{"id":"OKvUNlw6juZT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Предобработка данных","metadata":{"id":"_8k8-p8PLbP_"}},{"cell_type":"markdown","source":"Напишем свой класс FootballTeamsDataset для загрузки данных и работы с ними в PyTorch.","metadata":{"id":"uA5BwrSzNrWC"}},{"cell_type":"code","source":"class FootballTeamsDataset(Dataset):\n  teams_dict = {\n      'Arsenal': 0,\n      'Barcelona': 1,\n      'Bayern': 2,\n      'Chelsea': 3,\n      'Juventus': 4,\n      'Liverpool': 5,\n      'ManchesterCity': 6,\n      'ManchesterUnited': 7,\n      'PSG': 8,\n      'Real': 9,\n      '': -1,\n  }\n\n  def __init__(self, folder, transform=None):\n    self.transform = transform\n    self.folder = folder\n    self.files = []\n    self.teams = []\n\n    for file in listdir(folder):\n      if isdir(join(folder, file)):\n        # Set label as file's folder name\n        team_folder = join(folder, file)\n        self.files.extend([f for f in listdir(team_folder) if isfile(join(team_folder, f))])\n        self.teams.extend([file] * len(listdir(team_folder)))\n      elif isfile(join(folder, file)):\n        # If file is not inside folder, set empty label\n        self.files.append(file)\n        self.teams.append('')\n      \n  def __len__(self):\n    return len(self.files)\n  \n  def __getitem__(self, index):\n    if torch.is_tensor(index):\n      index = index.tolist()\n\n    img_name = self.files[index]\n    img_path = join(self.folder, self.teams[index], img_name)\n\n    img_label = self.teams_dict[self.teams[index]]\n\n    img = Image.open(img_path)\n    \n    if self.transform is not None:\n      img = self.transform(img)\n\n    return img, img_label, img_path","metadata":{"id":"ZW_MRbnUC10E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_folder = '/content/train'\ntest_folder = '/content/test'\n\norig_dataset = FootballTeamsDataset(train_folder)","metadata":{"id":"M9mxtg1YsTx1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Убедимся, что в тренировочном датасете отсутствует дисбаланс классов.","metadata":{"id":"wlRIhrlasMbM"}},{"cell_type":"code","source":"labels = []\nfor i in range(0, len(orig_dataset)):\n  labels.append(orig_dataset[i][1])\n\npd.Series(labels).hist()\nplt.title('Количество изображений по классам');","metadata":{"id":"q13CKLkBsPtl","outputId":"9fdc0593-cdac-4ad0-b05b-faf966729ac6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на несколько изображений из датасета.","metadata":{"id":"xI2v1UjMOBWP"}},{"cell_type":"code","source":"def visualize_samples(dataset, indices):\n  count = len(indices)\n  plt.figure(figsize=(count*4, 4))\n  plt.suptitle(f'{count} random samples')\n\n  for i, index in enumerate(indices):\n    x, y, _ = dataset[index]\n    x = np.array(x)\n\n    if len(x.shape) == 3:\n      x = x[0]\n\n    plt.subplot(1,count,i+1)\n    plt.title(f'Label: {y}')\n    plt.imshow(x)\n    plt.grid(False)\n    plt.axis('off')","metadata":{"id":"aNxASGQOIYrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_indices = np.random.choice(np.arange(len(orig_dataset)), 8, replace=False)\n\nvisualize_samples(orig_dataset, random_indices)","metadata":{"id":"wR1wwkjsKXA9","outputId":"90a818af-ece8-45c2-b39c-ac881deb2422"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на распределение разрешения изображений в датасете.","metadata":{"id":"rY4MtpD9OLks"}},{"cell_type":"code","source":"indices = np.arange(len(orig_dataset))\ndf_sizes = pd.DataFrame({'width': [], 'height': []})\nfor index in indices:\n  x, y, _ = orig_dataset[index]\n  width = x.size[0]\n  height = x.size[1]\n\n  df_sizes = df_sizes.append(pd.DataFrame({\n      'width': [width],\n      'height': [height],\n  }))\ndf_sizes = df_sizes.reset_index(drop=True)","metadata":{"id":"xat7ul9DObf9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sizes['width'].hist()\nplt.title('Распределение ширины изображений');","metadata":{"id":"hT0HaTMjPXC0","outputId":"429ccc05-d94e-4c48-bd72-9dc1ea9fc360"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sizes['height'].hist()\nplt.title('Распределение высоты изображений');","metadata":{"id":"1kTtLpLiQfY-","outputId":"18e1ef9a-803a-49a1-975e-08d36d1e3f8e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Большинство изображений имеет ширину и высоту около 1024 пикселей.","metadata":{"id":"n7kfKFu_XNRB"}},{"cell_type":"markdown","source":"Создадим объекты датасетов для тренировочной и тестовой части.\n\nИзменим разрешение входных изображений на 1024x1024, преобразуем их в тензоры и нормализуем. Для тренировочного датасета так же добавим аугментацию.","metadata":{"id":"a55jGmuprw4i"}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n  transforms.Resize((1024, 1024)),\n  transforms.ColorJitter(brightness=.5, saturation=.5, hue=.3),\n  transforms.RandomRotation(30, interpolation=transforms.InterpolationMode.BILINEAR),\n  transforms.ToTensor(),\n  transforms.Normalize((0.5), (0.5)),\n])\n\ntest_transform = transforms.Compose([\n  transforms.Resize((1024, 1024)),\n  transforms.ToTensor(),\n  transforms.Normalize((0.5), (0.5)),\n])\n\ntrain_dataset = FootballTeamsDataset(train_folder, transform=train_transform)\ntest_dataset = FootballTeamsDataset(test_folder, transform=test_transform)","metadata":{"id":"zw6vnagXv_Oe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на изображения с аугментацией.","metadata":{"id":"1uaRxkJBTfnj"}},{"cell_type":"code","source":"visualize_samples(train_dataset, random_indices)","metadata":{"id":"UB61cnCCSJbB","outputId":"ac9a9857-5c60-4a7a-b7e7-2c73eba7a7d0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Разобъём тренировочный датасет на тренировочную и валидационную части.\n\nСоздадим загрузчики для тренировочных, валидационных и тестовых данных.","metadata":{"id":"ln1kBKY3TsI1"}},{"cell_type":"code","source":"np.random.seed(69)\n\nbatch_size = 8\n\n# Get data indices\ndata_size = len(train_dataset)\nvalidation_split = .2\nsplit = int(np.floor(validation_split * data_size))\nindices = list(range(data_size))\nnp.random.shuffle(indices)\n\n# Create train and validation data loaders\ntrain_indices, val_indices = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n                                           sampler=train_sampler)\nval_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n                                         sampler=val_sampler)\n\n# Create test data loader\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1)","metadata":{"id":"DvR0yLENv3q1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Создание модели","metadata":{"id":"FxXkYYM5vtqH"}},{"cell_type":"markdown","source":"Создадим модель нейросети с четырьмя свёрточными слоями и тремя полносвязными. Добавим batch normalization и dropout для регуляризации.","metadata":{"id":"ypbinZP2UTdy"}},{"cell_type":"code","source":"class Net(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.conv1 = nn.Conv2d(1, 16, 5, padding=2)\n    self.conv2 = nn.Conv2d(16, 32, 5, padding=2)\n    self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n    self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n    self.pool = nn.MaxPool2d(4)\n    self.batchnorm16 = nn.BatchNorm2d(16)\n    self.batchnorm32 = nn.BatchNorm2d(32)\n    self.batchnorm64 = nn.BatchNorm2d(64)\n    self.dropout = nn.Dropout(p=0.2)\n    self.fc1 = nn.Linear(128 * 4 * 4, 512)\n    self.fc2 = nn.Linear(512, 256)\n    self.fc3 = nn.Linear(256, 10)\n  \n  def forward(self, x):\n    x = self.batchnorm16(self.pool(F.relu(self.conv1(x))))\n    x = self.batchnorm32(self.pool(F.relu(self.conv2(x))))\n    x = self.batchnorm64(self.pool(F.relu(self.conv3(x))))\n    x = self.pool(F.relu(self.conv4(x)))\n    x = torch.flatten(x, 1)\n    x = self.dropout(F.relu(self.fc1(x)))\n    x = self.dropout(F.relu(self.fc2(x)))\n    x = self.fc3(x)\n    return x","metadata":{"id":"qajKkrRRr1Xa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Обучение модели","metadata":{"id":"KuTmhLSlvxhR"}},{"cell_type":"markdown","source":"Функция обучения модели принимает на вход саму модель, загрузчики тренировочных и валидационных данных, loss функцию, оптимизатор, scheduler (опционально) и количество эпох для обучения.\n\nПосле обучения каждой эпохи рассчитывается метрика для тренировочных и валидационных данных, она выводятся в консоль, а обученная модель сохраняется на диск.","metadata":{"id":"DdGzLqIHUvob"}},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, loss, optimizer, scheduler, num_epochs):\n  best_val = 1\n  loss_history = []\n  train_history = []\n  val_history = []\n\n  for epoch in range(num_epochs):\n    model.train() # Enter train mode\n    \n    loss_accum = 0\n    predicted_labels = []\n    real_labels = []\n    for x, y, _ in tqdm(train_loader):\n      # Move data to GPU\n      inputs, labels = x.to(device), y.to(device)\n      # Make prediction\n      prediction = model(inputs)\n      # Calculate loss\n      loss_value = loss(prediction, labels)\n      # Optimize loss function\n      optimizer.zero_grad()\n      loss_value.backward()\n      optimizer.step()\n      # Save real and predicted labels to calculate score\n      _, predicted = torch.max(prediction, 1)\n      predicted_labels.extend(predicted.tolist())\n      real_labels.extend(labels.tolist())\n\n      # Clear GPU memeory\n      del inputs\n      del labels\n\n      loss_accum += loss_value\n\n    ave_loss = loss_accum / len(train_loader)\n    train_score = f1_score(real_labels, predicted_labels, average='macro')\n    val_score = compute_f1(model, val_loader)\n    \n    loss_history.append(float(ave_loss))\n    train_history.append(train_score)\n    val_history.append(val_score)\n\n    if scheduler:\n      scheduler.step()\n\n    if val_score < best_val:\n      best_val = val_score\n      torch.save(model.state_dict(), '/content/models/best_model.pt')\n    torch.save(model.state_dict(), '/content/models/model.pt')\n    \n    print(f'Epoch: {epoch+1}/{num_epochs}, Average loss: {ave_loss}, Train score: {train_score}, Val score: {val_score}')\n      \n  return loss_history, train_history, val_history\n\ndef compute_f1(model, loader):\n    model.eval() # Evaluation mode\n\n    predicted_labels = []\n    real_labels = []\n    for x, y, _ in tqdm(loader):\n      # Move data to GPU\n      inputs, labels = x.to(device), y.to(device)\n      # Make prediction\n      prediction = model(inputs)\n      # Save real and predicted labels to calculate score\n      _, predicted = torch.max(prediction, 1)\n      predicted_labels.extend(predicted.tolist())\n      real_labels.extend(labels.tolist())\n\n      # Clear GPU memeory\n      del inputs\n      del labels\n    \n    score = f1_score(real_labels, predicted_labels, average='macro')\n    return score","metadata":{"id":"qq3tiLRUwV6h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Инициализируем модель и перенесём её на GPU.\n\nТакже создадим объекты для функции потерь и оптимизатора Adam с параметрами скорости обучения $lr=3*10^{-4}$ и коэффициента регуляризации $weight\\_decay=10^{-4}$\n","metadata":{"id":"Ej5uIBV7WY8_"}},{"cell_type":"code","source":"model = Net().to(device)\n\nloss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\noptimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-4)\n#scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=20, T_mult=2, eta_min=1e-6)","metadata":{"id":"KtK0LqAwv1Cr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Запустим обучение модели на 30 эпох.","metadata":{"id":"mJL1baKGXbwK"}},{"cell_type":"code","source":"%%time\nloss_history, train_history, val_history = train_model(model, train_loader, val_loader, loss, optimizer, None, 30)","metadata":{"id":"CFJVGBrhwYLX","outputId":"e06c5bf7-3ae2-46cc-da0c-7b129c418888"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сохраним полученную модель на диск.","metadata":{"id":"9IS_ukKSXgF9"}},{"cell_type":"code","source":"torch.save(model.state_dict(), '/content/models/model_30ep.pt')","metadata":{"id":"gzsr0PqRlB4n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Анализ обученной модели","metadata":{"id":"hchePAQ1ZP81"}},{"cell_type":"markdown","source":"Визуализируем графики функции потерь и метрики.","metadata":{"id":"pv5qYUxeXjn_"}},{"cell_type":"code","source":"plt.plot(loss_history)\n\nplt.title('Train loss');","metadata":{"id":"IK4niH7xMj-8","outputId":"2a42070d-2188-445c-8a62-26bd3d119067"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_history)\nplt.plot(val_history)\n\nplt.legend(['Train', 'Validation'])\nplt.title('F1 score');","metadata":{"id":"C4zO9Koykyft","outputId":"f3de488e-1105-46db-e50d-601b228b749e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на ошибки модели.","metadata":{"id":"uzR0vRzAaBM2"}},{"cell_type":"code","source":"df_pred = pd.DataFrame({'path': [], 'real_label': [], 'pred_label': []})\n\nmodel.eval() # Evaluation mode\nfor x, y, path in tqdm(val_loader):\n  # Predict the label\n  inputs = x.to(device)\n  prediction = model(inputs)\n  _, predicted = torch.max(prediction.data, 1)\n\n  df_pred = df_pred.append(pd.DataFrame({\n      'path': path,\n      'real_label': y,\n      'pred_label': predicted.cpu().detach().numpy(),\n  }))\ndf_pred['real_label'] = df_pred['real_label'].astype(int)\ndf_pred['pred_label'] = df_pred['pred_label'].astype(int)\ndf_pred = df_pred.reset_index(drop=True)","metadata":{"id":"5jgPIpBmZgCN","outputId":"e02eb42c-61da-474e-a3fc-aa08c8d4bc6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_errors = df_pred[df_pred['real_label'] != df_pred['pred_label']].reset_index(drop=True)\nsns.heatmap(confusion_matrix(df_errors['real_label'], df_errors['pred_label']));","metadata":{"id":"uSfc0MhjcQQn","outputId":"81a74962-aac0-4f78-b853-f74495b187be"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Какой-то связи между командами и ошибками модели не видно. Чаще всего модель ошибается классифицируя форму Barcelona как форму Juventus.\n\nПосмотрим на сами изображения, на которых ошибается модель.","metadata":{"id":"6oczLa65jnWi"}},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\ncols = 5\nrows = 4\nrandom_indices = np.random.choice(np.arange(df_errors.shape[0]), cols * rows, replace=False)\nfor n, index in enumerate(random_indices):\n  fig.add_subplot(rows, cols, n+1)\n  plt.imshow(Image.open(df_errors.iloc[index]['path']))\n  plt.grid(False)\n  plt.axis('off')","metadata":{"id":"HZ7iHbZxbcZC","outputId":"513acfc8-0572-4f5a-e768-c85da9b364bc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Предсказания модели","metadata":{"id":"us0m9c-jZKf0"}},{"cell_type":"markdown","source":"Функция generate_submission_file генерирует файл с предсказаниями модели на тестовых данных.","metadata":{"id":"3xaEXhN2XqTD"}},{"cell_type":"code","source":"def generate_sumbission_file(model, test_loader, file_name='submission'):\n  submission_df = pd.DataFrame({'img_name': [], 'label': []})\n\n  model.eval() # Evaluation mode\n  for x, y, path in tqdm(test_loader):\n    # Predict the label\n    inputs = x.to(device)\n    prediction = model(inputs)\n    _, predicted = torch.max(prediction.data, 1)\n\n    # Save prediction\n    img_name = path[0]\n    img_name = img_name[img_name.rfind('/')+1:]\n    submission_df = submission_df.append(pd.DataFrame({\n        'img_name': [img_name],\n        'label': [predicted.item()]\n    }))\n  # Convert labels from float to int\n  submission_df['label'] = submission_df['label'].astype(int)\n  submission_df = submission_df.reset_index(drop=True)\n\n  # Save submissions dataframe to file\n  path = f'/content/submissions/{file_name}.csv'\n  submission_df.to_csv(path, index=False)\n\n  print(f'\\nSubmission file saved to: {path}')","metadata":{"id":"Qo3KAO6zAXH_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сохраним предсказания модели.","metadata":{"id":"1iSJVF-QX9qp"}},{"cell_type":"code","source":"generate_sumbission_file(model, test_loader, 'submission1')","metadata":{"id":"J8PqfuHBA54o","outputId":"d92d96af-3be9-4ca7-c1e8-091293d3b402"},"execution_count":null,"outputs":[]}]}